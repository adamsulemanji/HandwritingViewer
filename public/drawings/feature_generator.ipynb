{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029aebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "def compute_features(json_data, features):\n",
    "    \"\"\"\n",
    "    Compute requested features from a JSON object representing a drawing.\n",
    "\n",
    "    Args:\n",
    "        json_data (dict): JSON object representing a drawing with 'strokes' field.\n",
    "        features (list): List of features to compute. Each feature is a string.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing computed features for the drawing.\n",
    "    \"\"\"\n",
    "    # Extract strokes from the JSON data\n",
    "    strokes = json_data.get('strokes', [])\n",
    "    \n",
    "    # Initialize dictionary to store computed features\n",
    "    computed_features = {}\n",
    "\n",
    "    # Compute requested features\n",
    "    for feature in features:\n",
    "        if feature == 'total_strokes':\n",
    "            # Total number of strokes in the drawing\n",
    "            computed_features['total_strokes'] = len(strokes)\n",
    "        \n",
    "        elif feature == 'total_points':\n",
    "            # Total number of points in all strokes combined\n",
    "            total_points = sum(len(stroke) for stroke in strokes)\n",
    "            computed_features['total_points'] = total_points\n",
    "        \n",
    "        elif feature == 'average_points_per_stroke':\n",
    "            # Average number of points per stroke\n",
    "            if len(strokes) > 0:\n",
    "                avg_points_per_stroke = sum(len(stroke) for stroke in strokes) / len(strokes)\n",
    "            else:\n",
    "                avg_points_per_stroke = 0\n",
    "            computed_features['average_points_per_stroke'] = avg_points_per_stroke\n",
    "        \n",
    "        elif feature == 'drawing_duration':\n",
    "            # Duration of the drawing (time between first and last point)\n",
    "            if strokes:\n",
    "                start_time = min(min(point['t'] for point in stroke) for stroke in strokes)\n",
    "                end_time = max(max(point['t'] for point in stroke) for stroke in strokes)\n",
    "                drawing_duration = end_time - start_time\n",
    "            else:\n",
    "                drawing_duration = 0\n",
    "            computed_features['drawing_duration'] = drawing_duration\n",
    "        \n",
    "        elif feature == 'distance_first_to_last_point':\n",
    "            # Distance between the first and last point of all strokes combined\n",
    "            if strokes:\n",
    "                first_point = strokes[0][0]\n",
    "                last_point = strokes[-1][-1]\n",
    "                distance = math.sqrt((last_point['x'] - first_point['x'])**2 + (last_point['y'] - first_point['y'])**2)\n",
    "            else:\n",
    "                distance = 0\n",
    "            computed_features['distance_first_to_last_point'] = distance\n",
    "        \n",
    "        elif feature == 'convex_hull_to_bounding_rectangle_ratio':\n",
    "            # Ratio of area of convex hull to area of bounding rectangle\n",
    "            if strokes:\n",
    "                # Collect all points from all strokes\n",
    "                all_points = [(point['x'], point['y']) for stroke in strokes for point in stroke]\n",
    "                \n",
    "                # Calculate bounding rectangle area\n",
    "                min_x = min(point[0] for point in all_points)\n",
    "                max_x = max(point[0] for point in all_points)\n",
    "                min_y = min(point[1] for point in all_points)\n",
    "                max_y = max(point[1] for point in all_points)\n",
    "                bounding_rectangle_area = (max_x - min_x) * (max_y - min_y)\n",
    "                \n",
    "                # Calculate convex hull area\n",
    "                hull = ConvexHull(all_points)\n",
    "                convex_hull_area = hull.area\n",
    "                \n",
    "                # Compute the ratio\n",
    "                if bounding_rectangle_area > 0:\n",
    "                    ratio = convex_hull_area / bounding_rectangle_area\n",
    "                else:\n",
    "                    ratio = 0\n",
    "            else:\n",
    "                ratio = 0\n",
    "            computed_features['convex_hull_to_bounding_rectangle_ratio'] = ratio\n",
    "        \n",
    "        # Add more features as needed...\n",
    "\n",
    "    return computed_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6694aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Features:\n",
      "total_strokes: 1\n",
      "total_points: 1130\n",
      "average_points_per_stroke: 1130.0\n",
      "drawing_duration: 3.8226873874664307\n",
      "distance_first_to_last_point: 163.24827717314508\n",
      "convex_hull_to_bounding_rectangle_ratio: 0.010176624297020185\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to load JSON data from file\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n",
    "\n",
    "# Example JSON file path (replace with your actual file path)\n",
    "json_file_path = 'bad_A_12.json'\n",
    "\n",
    "# List of features to compute\n",
    "requested_features = [\n",
    "    'total_strokes', \n",
    "    'total_points', \n",
    "    'average_points_per_stroke', \n",
    "    'drawing_duration',\n",
    "    'distance_first_to_last_point',\n",
    "    'convex_hull_to_bounding_rectangle_ratio'\n",
    "]\n",
    "\n",
    "# Load JSON data from file\n",
    "drawing_data = load_json_file(json_file_path)\n",
    "\n",
    "# Compute features for the drawing data\n",
    "computed_features = compute_features(drawing_data, requested_features)\n",
    "\n",
    "# Print the computed features\n",
    "print(\"Computed Features:\")\n",
    "for feature, value in computed_features.items():\n",
    "    print(f\"{feature}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7093354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: {'total_strokes': 2, 'total_points': 561, 'average_points_per_stroke': 280.5, 'drawing_duration': 1.3009135723114014, 'distance_first_to_last_point': 337.0370899470858, 'convex_hull_to_bounding_rectangle_ratio': 0.012089949476637052, 'label': 0}\n",
      "Features: {'total_strokes': 2, 'total_points': 496, 'average_points_per_stroke': 248.0, 'drawing_duration': 1.8920116424560547, 'distance_first_to_last_point': 168.5496959356498, 'convex_hull_to_bounding_rectangle_ratio': 0.04109225623668547, 'label': 0}\n",
      "Features: {'total_strokes': 3, 'total_points': 985, 'average_points_per_stroke': 328.3333333333333, 'drawing_duration': 6.094426870346069, 'distance_first_to_last_point': 244.1823089414956, 'convex_hull_to_bounding_rectangle_ratio': 0.012731247823205729, 'label': 0}\n",
      "Features: {'total_strokes': 1, 'total_points': 1130, 'average_points_per_stroke': 1130.0, 'drawing_duration': 3.8226873874664307, 'distance_first_to_last_point': 163.24827717314508, 'convex_hull_to_bounding_rectangle_ratio': 0.010176624297020185, 'label': 0}\n",
      "Features: {'total_strokes': 2, 'total_points': 1059, 'average_points_per_stroke': 529.5, 'drawing_duration': 2.762094736099243, 'distance_first_to_last_point': 727.303237996367, 'convex_hull_to_bounding_rectangle_ratio': 0.005231270580417851, 'label': 0}\n",
      "Features: {'total_strokes': 2, 'total_points': 346, 'average_points_per_stroke': 173.0, 'drawing_duration': 0.8874139785766602, 'distance_first_to_last_point': 402.4425424827748, 'convex_hull_to_bounding_rectangle_ratio': 0.008142560206272326, 'label': 0}\n",
      "Features: {'total_strokes': 1, 'total_points': 705, 'average_points_per_stroke': 705.0, 'drawing_duration': 1.5987460613250732, 'distance_first_to_last_point': 181.89282558693733, 'convex_hull_to_bounding_rectangle_ratio': 0.010124779675794785, 'label': 0}\n",
      "Features: {'total_strokes': 3, 'total_points': 359, 'average_points_per_stroke': 119.66666666666667, 'drawing_duration': 2.2959470748901367, 'distance_first_to_last_point': 273.82658746002005, 'convex_hull_to_bounding_rectangle_ratio': 0.007820390884896573, 'label': 0}\n",
      "Features: {'total_strokes': 2, 'total_points': 848, 'average_points_per_stroke': 424.0, 'drawing_duration': 1.948437213897705, 'distance_first_to_last_point': 339.7131142596647, 'convex_hull_to_bounding_rectangle_ratio': 0.010272933455793986, 'label': 0}\n",
      "Features: {'total_strokes': 3, 'total_points': 630, 'average_points_per_stroke': 210.0, 'drawing_duration': 4.451772212982178, 'distance_first_to_last_point': 181.11046352985792, 'convex_hull_to_bounding_rectangle_ratio': 0.012813913096922404, 'label': 0}\n",
      "Features: {'total_strokes': 3, 'total_points': 498, 'average_points_per_stroke': 166.0, 'drawing_duration': 1.7512805461883545, 'distance_first_to_last_point': 398.1205847478877, 'convex_hull_to_bounding_rectangle_ratio': 0.009055500681222947, 'label': 0}\n",
      "Features: {'total_strokes': 3, 'total_points': 879, 'average_points_per_stroke': 293.0, 'drawing_duration': 6.646244525909424, 'distance_first_to_last_point': 254.19087316424248, 'convex_hull_to_bounding_rectangle_ratio': 0.01246150247318085, 'label': 0}\n",
      "Features: {'total_strokes': 2, 'total_points': 520, 'average_points_per_stroke': 260.0, 'drawing_duration': 1.7103338241577148, 'distance_first_to_last_point': 93.03762679690406, 'convex_hull_to_bounding_rectangle_ratio': 0.020038925905375458, 'label': 0}\n",
      "Features: {'total_strokes': 2, 'total_points': 1281, 'average_points_per_stroke': 640.5, 'drawing_duration': 3.7469472885131836, 'distance_first_to_last_point': 388.9588667198628, 'convex_hull_to_bounding_rectangle_ratio': 0.00899521569328756, 'label': 0}\n",
      "Features: {'total_strokes': 2, 'total_points': 835, 'average_points_per_stroke': 417.5, 'drawing_duration': 2.0439858436584473, 'distance_first_to_last_point': 312.00160255998685, 'convex_hull_to_bounding_rectangle_ratio': 0.009652423036197516, 'label': 0}\n",
      "Features: {'total_strokes': 2, 'total_points': 897, 'average_points_per_stroke': 448.5, 'drawing_duration': 1.8507823944091797, 'distance_first_to_last_point': 329.38882798297817, 'convex_hull_to_bounding_rectangle_ratio': 0.010990050731026916, 'label': 0}\n",
      "Features: {'total_strokes': 3, 'total_points': 419, 'average_points_per_stroke': 139.66666666666666, 'drawing_duration': 2.409276008605957, 'distance_first_to_last_point': 134.2013412749664, 'convex_hull_to_bounding_rectangle_ratio': 0.01154485773509716, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 559, 'average_points_per_stroke': 279.5, 'drawing_duration': 3.9604904651641846, 'distance_first_to_last_point': 278.4600509947522, 'convex_hull_to_bounding_rectangle_ratio': 0.013096759062789164, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 789, 'average_points_per_stroke': 394.5, 'drawing_duration': 2.747349977493286, 'distance_first_to_last_point': 280.7294070809113, 'convex_hull_to_bounding_rectangle_ratio': 0.012896100029878467, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 672, 'average_points_per_stroke': 336.0, 'drawing_duration': 5.884872198104858, 'distance_first_to_last_point': 317.1277345171816, 'convex_hull_to_bounding_rectangle_ratio': 0.01148446256748034, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 639, 'average_points_per_stroke': 319.5, 'drawing_duration': 7.47780442237854, 'distance_first_to_last_point': 307.0504844484047, 'convex_hull_to_bounding_rectangle_ratio': 0.012608691708577785, 'label': 1}\n",
      "Features: {'total_strokes': 3, 'total_points': 521, 'average_points_per_stroke': 173.66666666666666, 'drawing_duration': 2.565993309020996, 'distance_first_to_last_point': 383.5440000834324, 'convex_hull_to_bounding_rectangle_ratio': 0.010050855491993405, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 590, 'average_points_per_stroke': 295.0, 'drawing_duration': 4.623395204544067, 'distance_first_to_last_point': 480.7546151624548, 'convex_hull_to_bounding_rectangle_ratio': 0.009402447850231855, 'label': 1}\n",
      "Features: {'total_strokes': 3, 'total_points': 605, 'average_points_per_stroke': 201.66666666666666, 'drawing_duration': 7.350244760513306, 'distance_first_to_last_point': 235.16164653276266, 'convex_hull_to_bounding_rectangle_ratio': 0.013388431950248289, 'label': 1}\n",
      "Features: {'total_strokes': 3, 'total_points': 371, 'average_points_per_stroke': 123.66666666666667, 'drawing_duration': 2.769836664199829, 'distance_first_to_last_point': 185.41305239923105, 'convex_hull_to_bounding_rectangle_ratio': 0.012517363279613093, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 574, 'average_points_per_stroke': 287.0, 'drawing_duration': 2.1372275352478027, 'distance_first_to_last_point': 143.96180048887967, 'convex_hull_to_bounding_rectangle_ratio': 0.018563474227946356, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 794, 'average_points_per_stroke': 397.0, 'drawing_duration': 2.009718179702759, 'distance_first_to_last_point': 462.95248136282845, 'convex_hull_to_bounding_rectangle_ratio': 0.006593946809034668, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 540, 'average_points_per_stroke': 270.0, 'drawing_duration': 3.969778060913086, 'distance_first_to_last_point': 214.97906874856446, 'convex_hull_to_bounding_rectangle_ratio': 0.01165277788557654, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 894, 'average_points_per_stroke': 447.0, 'drawing_duration': 2.742713451385498, 'distance_first_to_last_point': 275.138147118861, 'convex_hull_to_bounding_rectangle_ratio': 0.011644571385645557, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 828, 'average_points_per_stroke': 414.0, 'drawing_duration': 3.1378860473632812, 'distance_first_to_last_point': 296.89223634174067, 'convex_hull_to_bounding_rectangle_ratio': 0.012391346828181193, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 598, 'average_points_per_stroke': 299.0, 'drawing_duration': 2.151970863342285, 'distance_first_to_last_point': 388.7235521549987, 'convex_hull_to_bounding_rectangle_ratio': 0.008719190746953005, 'label': 1}\n",
      "Features: {'total_strokes': 2, 'total_points': 626, 'average_points_per_stroke': 313.0, 'drawing_duration': 4.612611532211304, 'distance_first_to_last_point': 230.84193726444076, 'convex_hull_to_bounding_rectangle_ratio': 0.015746375941683387, 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n",
    "\n",
    "def compute_features(json_data, features):\n",
    "    strokes = json_data.get('strokes', [])\n",
    "    computed_features = {}\n",
    "\n",
    "    for feature in features:\n",
    "        if feature == 'total_strokes':\n",
    "            computed_features['total_strokes'] = len(strokes)\n",
    "        \n",
    "        elif feature == 'total_points':\n",
    "            total_points = sum(len(stroke) for stroke in strokes)\n",
    "            computed_features['total_points'] = total_points\n",
    "        \n",
    "        elif feature == 'average_points_per_stroke':\n",
    "            if len(strokes) > 0:\n",
    "                avg_points_per_stroke = sum(len(stroke) for stroke in strokes) / len(strokes)\n",
    "            else:\n",
    "                avg_points_per_stroke = 0\n",
    "            computed_features['average_points_per_stroke'] = avg_points_per_stroke\n",
    "        \n",
    "        elif feature == 'drawing_duration':\n",
    "            if strokes:\n",
    "                start_time = min(min(point['t'] for point in stroke) for stroke in strokes)\n",
    "                end_time = max(max(point['t'] for point in stroke) for stroke in strokes)\n",
    "                drawing_duration = end_time - start_time\n",
    "            else:\n",
    "                drawing_duration = 0\n",
    "            computed_features['drawing_duration'] = drawing_duration\n",
    "        \n",
    "        elif feature == 'distance_first_to_last_point':\n",
    "            if strokes:\n",
    "                first_point = strokes[0][0]\n",
    "                last_point = strokes[-1][-1]\n",
    "                distance = math.sqrt((last_point['x'] - first_point['x'])**2 + (last_point['y'] - first_point['y'])**2)\n",
    "            else:\n",
    "                distance = 0\n",
    "            computed_features['distance_first_to_last_point'] = distance\n",
    "        \n",
    "        elif feature == 'convex_hull_to_bounding_rectangle_ratio':\n",
    "            if strokes:\n",
    "                all_points = [(point['x'], point['y']) for stroke in strokes for point in stroke]\n",
    "                min_x = min(point[0] for point in all_points)\n",
    "                max_x = max(point[0] for point in all_points)\n",
    "                min_y = min(point[1] for point in all_points)\n",
    "                max_y = max(point[1] for point in all_points)\n",
    "                bounding_rectangle_area = (max_x - min_x) * (max_y - min_y)\n",
    "                hull = ConvexHull(all_points)\n",
    "                convex_hull_area = hull.area\n",
    "                if bounding_rectangle_area > 0:\n",
    "                    ratio = convex_hull_area / bounding_rectangle_area\n",
    "                else:\n",
    "                    ratio = 0\n",
    "            else:\n",
    "                ratio = 0\n",
    "            computed_features['convex_hull_to_bounding_rectangle_ratio'] = ratio\n",
    "\n",
    "    return computed_features\n",
    "\n",
    "def process_drawing_files(folder_path, features):\n",
    "    drawing_data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.json') and ('bad_A_' in filename or 'good_A_' in filename):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            json_data = load_json_file(file_path)\n",
    "            computed_features = compute_features(json_data, features)\n",
    "\n",
    "            # Determine label based on filename prefix\n",
    "            if 'bad_A_' in filename:\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "\n",
    "            # Add computed features and label to the list\n",
    "            computed_features['label'] = label\n",
    "            drawing_data.append(computed_features)\n",
    "\n",
    "    return drawing_data\n",
    "\n",
    "# Specify the folder path where the JSON files are located\n",
    "folder_path = '.'  # Assuming JSON files are in the same directory as this script\n",
    "\n",
    "# List of features to compute\n",
    "requested_features = [\n",
    "    'total_strokes', \n",
    "    'total_points', \n",
    "    'average_points_per_stroke', \n",
    "    'drawing_duration',\n",
    "    'distance_first_to_last_point',\n",
    "    'convex_hull_to_bounding_rectangle_ratio'\n",
    "]\n",
    "\n",
    "# Process drawing files and compute features\n",
    "drawings_features = process_drawing_files(folder_path, requested_features)\n",
    "\n",
    "# Print out computed features with labels\n",
    "for drawing in drawings_features:\n",
    "    print(\"Features:\", drawing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3971a14",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 115>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Initialize and train a logistic regression model\u001b[39;00m\n\u001b[0;32m    114\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m--> 115\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m    118\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1138\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1138\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1146\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[1;32m-> 1074\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n",
    "\n",
    "def compute_features(json_data, features):\n",
    "    strokes = json_data.get('strokes', [])\n",
    "    computed_features = {}\n",
    "\n",
    "    for feature in features:\n",
    "        if feature == 'total_strokes':\n",
    "            computed_features['total_strokes'] = len(strokes)\n",
    "        \n",
    "        elif feature == 'total_points':\n",
    "            total_points = sum(len(stroke) for stroke in strokes)\n",
    "            computed_features['total_points'] = total_points\n",
    "        \n",
    "        elif feature == 'average_points_per_stroke':\n",
    "            if len(strokes) > 0:\n",
    "                avg_points_per_stroke = sum(len(stroke) for stroke in strokes) / len(strokes)\n",
    "            else:\n",
    "                avg_points_per_stroke = 0\n",
    "            computed_features['average_points_per_stroke'] = avg_points_per_stroke\n",
    "        \n",
    "        elif feature == 'drawing_duration':\n",
    "            if strokes:\n",
    "                start_time = min(min(point['t'] for point in stroke) for stroke in strokes)\n",
    "                end_time = max(max(point['t'] for point in stroke) for stroke in strokes)\n",
    "                drawing_duration = end_time - start_time\n",
    "            else:\n",
    "                drawing_duration = 0\n",
    "            computed_features['drawing_duration'] = drawing_duration\n",
    "        \n",
    "        elif feature == 'distance_first_to_last_point':\n",
    "            if strokes:\n",
    "                first_point = strokes[0][0]\n",
    "                last_point = strokes[-1][-1]\n",
    "                distance = math.sqrt((last_point['x'] - first_point['x'])**2 + (last_point['y'] - first_point['y'])**2)\n",
    "            else:\n",
    "                distance = 0\n",
    "            computed_features['distance_first_to_last_point'] = distance\n",
    "        \n",
    "        elif feature == 'convex_hull_to_bounding_rectangle_ratio':\n",
    "            if strokes:\n",
    "                all_points = [(point['x'], point['y']) for stroke in strokes for point in stroke]\n",
    "                min_x = min(point[0] for point in all_points)\n",
    "                max_x = max(point[0] for point in all_points)\n",
    "                min_y = min(point[1] for point in all_points)\n",
    "                max_y = max(point[1] for point in all_points)\n",
    "                bounding_rectangle_area = (max_x - min_x) * (max_y - min_y)\n",
    "                hull = ConvexHull(all_points)\n",
    "                convex_hull_area = hull.area\n",
    "                if bounding_rectangle_area > 0:\n",
    "                    ratio = convex_hull_area / bounding_rectangle_area\n",
    "                else:\n",
    "                    ratio = 0\n",
    "            else:\n",
    "                ratio = 0\n",
    "            computed_features['convex_hull_to_bounding_rectangle_ratio'] = ratio\n",
    "\n",
    "    return computed_features\n",
    "\n",
    "def process_drawing_files(folder_path, features):\n",
    "    drawing_data = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.json') and ('bad_A_' in filename or 'good_A_' in filename):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            json_data = load_json_file(file_path)\n",
    "            computed_features = compute_features(json_data, features)\n",
    "\n",
    "            # Determine label based on filename prefix\n",
    "            if 'bad_A_' in filename:\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "\n",
    "            # Add computed features and label to the lists\n",
    "            drawing_data.append(computed_features)\n",
    "            labels.append(label)\n",
    "\n",
    "    return drawing_data, labels\n",
    "\n",
    "# Specify the folder path where the JSON files are located\n",
    "folder_path = '.'  # Assuming JSON files are in the same directory as this script\n",
    "\n",
    "# List of features to compute\n",
    "requested_features = [\n",
    "    'total_strokes', \n",
    "    'total_points', \n",
    "    'average_points_per_stroke', \n",
    "    'drawing_duration',\n",
    "    'distance_first_to_last_point',\n",
    "    'convex_hull_to_bounding_rectangle_ratio'\n",
    "]\n",
    "\n",
    "# Process drawing files and extract features and labels\n",
    "X, y = process_drawing_files(folder_path, requested_features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6076440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n",
    "\n",
    "def compute_features(json_data, features):\n",
    "    strokes = json_data.get('strokes', [])\n",
    "    computed_features = {}\n",
    "\n",
    "    for feature in features:\n",
    "        if feature == 'total_strokes':\n",
    "            computed_features['total_strokes'] = len(strokes)\n",
    "        \n",
    "        elif feature == 'total_points':\n",
    "            total_points = sum(len(stroke) for stroke in strokes)\n",
    "            computed_features['total_points'] = total_points\n",
    "        \n",
    "        elif feature == 'average_points_per_stroke':\n",
    "            if len(strokes) > 0:\n",
    "                avg_points_per_stroke = sum(len(stroke) for stroke in strokes) / len(strokes)\n",
    "            else:\n",
    "                avg_points_per_stroke = 0\n",
    "            computed_features['average_points_per_stroke'] = avg_points_per_stroke\n",
    "        \n",
    "        elif feature == 'drawing_duration':\n",
    "            if strokes:\n",
    "                start_times = [min(point['t'] for point in stroke) for stroke in strokes if stroke]\n",
    "                end_times = [max(point['t'] for point in stroke) for stroke in strokes if stroke]\n",
    "                drawing_duration = max(end_times) - min(start_times)\n",
    "            else:\n",
    "                drawing_duration = 0\n",
    "            computed_features['drawing_duration'] = drawing_duration\n",
    "        \n",
    "        elif feature == 'distance_first_to_last_point':\n",
    "            if strokes:\n",
    "                first_point = strokes[0][0]\n",
    "                last_point = strokes[-1][-1]\n",
    "                distance = math.sqrt((last_point['x'] - first_point['x'])**2 + (last_point['y'] - first_point['y'])**2)\n",
    "            else:\n",
    "                distance = 0\n",
    "            computed_features['distance_first_to_last_point'] = distance\n",
    "        \n",
    "        elif feature == 'convex_hull_to_bounding_rectangle_ratio':\n",
    "            if strokes:\n",
    "                all_points = [(point['x'], point['y']) for stroke in strokes for point in stroke]\n",
    "                if all_points:\n",
    "                    min_x = min(point[0] for point in all_points)\n",
    "                    max_x = max(point[0] for point in all_points)\n",
    "                    min_y = min(point[1] for point in all_points)\n",
    "                    max_y = max(point[1] for point in all_points)\n",
    "                    bounding_rectangle_area = (max_x - min_x) * (max_y - min_y)\n",
    "                    if bounding_rectangle_area > 0:\n",
    "                        hull = ConvexHull(all_points)\n",
    "                        convex_hull_area = hull.area\n",
    "                        ratio = convex_hull_area / bounding_rectangle_area\n",
    "                    else:\n",
    "                        ratio = 0\n",
    "                else:\n",
    "                    ratio = 0\n",
    "            else:\n",
    "                ratio = 0\n",
    "            computed_features['convex_hull_to_bounding_rectangle_ratio'] = ratio\n",
    "\n",
    "    return computed_features\n",
    "\n",
    "def process_drawing_files(folder_path, features):\n",
    "    drawing_data = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.json') and ('bad_A_' in filename or 'good_A_' in filename):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            json_data = load_json_file(file_path)\n",
    "            computed_features = compute_features(json_data, features)\n",
    "\n",
    "            # Determine label based on filename prefix\n",
    "            if 'bad_A_' in filename:\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "\n",
    "            # Add computed features and label to the lists\n",
    "            drawing_data.append(computed_features)\n",
    "            labels.append(label)\n",
    "\n",
    "    return drawing_data, labels\n",
    "\n",
    "# Specify the folder path where the JSON files are located\n",
    "folder_path = '.'  # Assuming JSON files are in the same directory as this script\n",
    "\n",
    "# List of features to compute\n",
    "requested_features = [\n",
    "    'total_strokes', \n",
    "    'total_points', \n",
    "    'average_points_per_stroke', \n",
    "    'drawing_duration',\n",
    "    'distance_first_to_last_point',\n",
    "    'convex_hull_to_bounding_rectangle_ratio'\n",
    "]\n",
    "\n",
    "# Process drawing files and extract features and labels\n",
    "X, y = process_drawing_files(folder_path, requested_features)\n",
    "\n",
    "# Convert features (X) into a numpy array for training\n",
    "X = np.array([list(d.values()) for d in X])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502f5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.57         7\n",
      "   macro avg       0.58      0.58      0.57         7\n",
      "weighted avg       0.60      0.57      0.57         7\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 139>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    141\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_test[i])\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Visualize SHAP values for the chosen instance\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m shap\u001b[38;5;241m.\u001b[39mforce_plot(\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_value\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, shap_values[\u001b[38;5;241m1\u001b[39m], X_test[i], feature_names\u001b[38;5;241m=\u001b[39mrequested_features)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Save the plot (optional)\u001b[39;00m\n\u001b[0;32m    147\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshap_plot_instance_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Save the plot with a unique filename for each instance\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import shap\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n",
    "\n",
    "def compute_features(json_data, features):\n",
    "    strokes = json_data.get('strokes', [])\n",
    "    computed_features = {}\n",
    "\n",
    "    for feature in features:\n",
    "        if feature == 'total_strokes':\n",
    "            computed_features['total_strokes'] = len(strokes)\n",
    "        \n",
    "        elif feature == 'total_points':\n",
    "            total_points = sum(len(stroke) for stroke in strokes)\n",
    "            computed_features['total_points'] = total_points\n",
    "        \n",
    "        elif feature == 'average_points_per_stroke':\n",
    "            if len(strokes) > 0:\n",
    "                avg_points_per_stroke = sum(len(stroke) for stroke in strokes) / len(strokes)\n",
    "            else:\n",
    "                avg_points_per_stroke = 0\n",
    "            computed_features['average_points_per_stroke'] = avg_points_per_stroke\n",
    "        \n",
    "        elif feature == 'drawing_duration':\n",
    "            if strokes:\n",
    "                start_times = [min(point['t'] for point in stroke) for stroke in strokes if stroke]\n",
    "                end_times = [max(point['t'] for point in stroke) for stroke in strokes if stroke]\n",
    "                drawing_duration = max(end_times) - min(start_times)\n",
    "            else:\n",
    "                drawing_duration = 0\n",
    "            computed_features['drawing_duration'] = drawing_duration\n",
    "        \n",
    "        elif feature == 'distance_first_to_last_point':\n",
    "            if strokes:\n",
    "                first_point = strokes[0][0]\n",
    "                last_point = strokes[-1][-1]\n",
    "                distance = math.sqrt((last_point['x'] - first_point['x'])**2 + (last_point['y'] - first_point['y'])**2)\n",
    "            else:\n",
    "                distance = 0\n",
    "            computed_features['distance_first_to_last_point'] = distance\n",
    "        \n",
    "        elif feature == 'convex_hull_to_bounding_rectangle_ratio':\n",
    "            if strokes:\n",
    "                all_points = [(point['x'], point['y']) for stroke in strokes for point in stroke]\n",
    "                if all_points:\n",
    "                    min_x = min(point[0] for point in all_points)\n",
    "                    max_x = max(point[0] for point in all_points)\n",
    "                    min_y = min(point[1] for point in all_points)\n",
    "                    max_y = max(point[1] for point in all_points)\n",
    "                    bounding_rectangle_area = (max_x - min_x) * (max_y - min_y)\n",
    "                    if bounding_rectangle_area > 0:\n",
    "                        hull = ConvexHull(all_points)\n",
    "                        convex_hull_area = hull.area\n",
    "                        ratio = convex_hull_area / bounding_rectangle_area\n",
    "                    else:\n",
    "                        ratio = 0\n",
    "                else:\n",
    "                    ratio = 0\n",
    "            else:\n",
    "                ratio = 0\n",
    "            computed_features['convex_hull_to_bounding_rectangle_ratio'] = ratio\n",
    "\n",
    "    return computed_features\n",
    "\n",
    "def process_drawing_files(folder_path, features):\n",
    "    drawing_data = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.json') and ('bad_A_' in filename or 'good_A_' in filename):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            json_data = load_json_file(file_path)\n",
    "            computed_features = compute_features(json_data, features)\n",
    "\n",
    "            # Determine label based on filename prefix\n",
    "            if 'bad_A_' in filename:\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "\n",
    "            # Add computed features and label to the lists\n",
    "            drawing_data.append(computed_features)\n",
    "            labels.append(label)\n",
    "\n",
    "    return drawing_data, labels\n",
    "\n",
    "# Specify the folder path where the JSON files are located\n",
    "folder_path = '.'  # Assuming JSON files are in the same directory as this script\n",
    "\n",
    "# List of features to compute\n",
    "requested_features = [\n",
    "    'total_strokes', \n",
    "    'total_points', \n",
    "    'average_points_per_stroke', \n",
    "    'drawing_duration',\n",
    "    'distance_first_to_last_point',\n",
    "    'convex_hull_to_bounding_rectangle_ratio'\n",
    "]\n",
    "\n",
    "# Process drawing files and extract features and labels\n",
    "X, y = process_drawing_files(folder_path, requested_features)\n",
    "\n",
    "# Convert features (X) into a numpy array for training\n",
    "X = np.array([list(d.values()) for d in X])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Explain each prediction using SHAP\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot SHAP values for each prediction\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"Prediction {i+1}:\")\n",
    "    shap.force_plot(explainer.expected_value, shap_values[i], X_test[i], feature_names=requested_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4738c2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.90      0.83      0.84         7\n",
      "weighted avg       0.89      0.86      0.85         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n",
    "\n",
    "def compute_features(json_data, features):\n",
    "    strokes = json_data.get('strokes', [])\n",
    "    computed_features = {}\n",
    "\n",
    "    for feature in features:\n",
    "        if feature == 'total_strokes':\n",
    "            computed_features['total_strokes'] = len(strokes)\n",
    "        \n",
    "        elif feature == 'total_points':\n",
    "            total_points = sum(len(stroke) for stroke in strokes)\n",
    "            computed_features['total_points'] = total_points\n",
    "        \n",
    "        elif feature == 'average_points_per_stroke':\n",
    "            if len(strokes) > 0:\n",
    "                avg_points_per_stroke = sum(len(stroke) for stroke in strokes) / len(strokes)\n",
    "            else:\n",
    "                avg_points_per_stroke = 0\n",
    "            computed_features['average_points_per_stroke'] = avg_points_per_stroke\n",
    "        \n",
    "        elif feature == 'drawing_duration':\n",
    "            if strokes:\n",
    "                start_times = [min(point['t'] for point in stroke) for stroke in strokes if stroke]\n",
    "                end_times = [max(point['t'] for point in stroke) for stroke in strokes if stroke]\n",
    "                drawing_duration = max(end_times) - min(start_times)\n",
    "            else:\n",
    "                drawing_duration = 0\n",
    "            computed_features['drawing_duration'] = drawing_duration\n",
    "        \n",
    "        elif feature == 'distance_first_to_last_point':\n",
    "            if strokes:\n",
    "                first_point = strokes[0][0]\n",
    "                last_point = strokes[-1][-1]\n",
    "                distance = math.sqrt((last_point['x'] - first_point['x'])**2 + (last_point['y'] - first_point['y'])**2)\n",
    "            else:\n",
    "                distance = 0\n",
    "            computed_features['distance_first_to_last_point'] = distance\n",
    "        \n",
    "        elif feature == 'convex_hull_to_bounding_rectangle_ratio':\n",
    "            if strokes:\n",
    "                all_points = [(point['x'], point['y']) for stroke in strokes for point in stroke]\n",
    "                if all_points:\n",
    "                    min_x = min(point[0] for point in all_points)\n",
    "                    max_x = max(point[0] for point in all_points)\n",
    "                    min_y = min(point[1] for point in all_points)\n",
    "                    max_y = max(point[1] for point in all_points)\n",
    "                    bounding_rectangle_area = (max_x - min_x) * (max_y - min_y)\n",
    "                    if bounding_rectangle_area > 0:\n",
    "                        hull = ConvexHull(all_points)\n",
    "                        convex_hull_area = hull.area\n",
    "                        ratio = convex_hull_area / bounding_rectangle_area\n",
    "                    else:\n",
    "                        ratio = 0\n",
    "                else:\n",
    "                    ratio = 0\n",
    "            else:\n",
    "                ratio = 0\n",
    "            computed_features['convex_hull_to_bounding_rectangle_ratio'] = ratio\n",
    "\n",
    "    return computed_features\n",
    "\n",
    "def process_drawing_files(folder_path, features):\n",
    "    drawing_data = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.json') and ('bad_A_' in filename or 'good_A_' in filename):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            json_data = load_json_file(file_path)\n",
    "            computed_features = compute_features(json_data, features)\n",
    "\n",
    "            # Determine label based on filename prefix\n",
    "            if 'bad_A_' in filename:\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "\n",
    "            # Add computed features and label to the lists\n",
    "            drawing_data.append(computed_features)\n",
    "            labels.append(label)\n",
    "\n",
    "    return drawing_data, labels\n",
    "\n",
    "# Specify the folder path where the JSON files are located\n",
    "folder_path = '.'  # Assuming JSON files are in the same directory as this script\n",
    "\n",
    "# List of features to compute\n",
    "requested_features = [\n",
    "    'total_strokes', \n",
    "    'total_points', \n",
    "    'average_points_per_stroke', \n",
    "    'drawing_duration',\n",
    "    'distance_first_to_last_point',\n",
    "    'convex_hull_to_bounding_rectangle_ratio'\n",
    "]\n",
    "\n",
    "# Process drawing files and extract features and labels\n",
    "X, y = process_drawing_files(folder_path, requested_features)\n",
    "\n",
    "# Convert features (X) into a numpy array for training\n",
    "X = np.array([list(d.values()) for d in X])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a logistic regression model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984cb31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
